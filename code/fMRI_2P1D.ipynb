{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nilearn as nil\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from scipy import ndimage\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FmriDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir='/data/fmri/data', mask_path='/data/fmri/mask/caudate_mask.nii',\n",
    "                img_shape=(57, 68, 49, 135), img_timesteps=15):\n",
    "        self.data_dir = data_dir\n",
    "        self.img_timesteps = img_timesteps\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.mask_path, self.img_shape = mask_path, img_shape\n",
    "        self.samples = []\n",
    "        # Initialize the image indexes with their scores\n",
    "        self.index_data()\n",
    "        self.mask = self.read_mask()\n",
    "        self.class_weights = self.find_weights()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, score = self.samples[idx]\n",
    "        score = self.get_class(score)\n",
    "        img = self.read_image(img_path)\n",
    "        img = self.apply_mask(img)\n",
    "        img = self.apply_temporal_aug(img)\n",
    "        return img, score\n",
    "\n",
    "    def index_data(self):\n",
    "        \"\"\"\n",
    "        Stores all the image_paths with their respective scores/classes in the \n",
    "        \"\"\"\n",
    "        self.weights = {i:0 for i in range(5)}\n",
    "        for sub in os.listdir(self.data_dir):\n",
    "            sub_dir = os.path.join(self.data_dir, sub)\n",
    "            preproc_dir = os.path.join(sub_dir, f'{sub}.preproc')\n",
    "            for img_name in os.listdir(preproc_dir):\n",
    "                img_path = os.path.join(preproc_dir, img_name)\n",
    "                score = self.get_score(sub_dir, img_name)\n",
    "                score_class = self.get_class(score)\n",
    "                self.weights[score_class] += 1\n",
    "                self.samples.append((img_path, score))\n",
    "                \n",
    "    def get_class(self, score):\n",
    "        \"\"\"\n",
    "        Categorize each score into one of the five classes (bins)\n",
    "        Returns values from 0-4 (5 classes)\n",
    "        \"\"\"\n",
    "        if score < 1:\n",
    "            return 0\n",
    "        elif score >= 100:\n",
    "            return 4\n",
    "        else:\n",
    "            return score // 20\n",
    "        \n",
    "\n",
    "    def get_score(self, sub_dir, img_name):\n",
    "        score_file = '0back_VAS-f.1D' if '0back' in img_name else '2back_VAS-f.1D'\n",
    "        score_path = os.path.join(sub_dir, score_file)\n",
    "        with open(score_path, 'r') as s_f:\n",
    "            scores = [int(str(score.replace('\\n', ''))) for score in s_f]\n",
    "\n",
    "        task_num = img_name.split('.')[1]\n",
    "        score_num = int(task_num[-1:])\n",
    "        return scores[score_num]\n",
    "    \n",
    "    def read_image(self, img_path):\n",
    "        nX, nY, nZ, nT = self.img_shape\n",
    "        img = nil.image.load_img(img_path)\n",
    "        img = img.get_fdata()[:nX, :nY, :nZ, :nT]\n",
    "        img = torch.tensor(img, dtype=torch.float, device=self.device)\n",
    "        img = (img - img.mean()) / img.std()\n",
    "        return img\n",
    "    \n",
    "    def read_mask(self):\n",
    "        nX, nY, nZ, _ = self.img_shape\n",
    "        mask_img = nil.image.load_img(self.mask_path)\n",
    "        mask_img = mask_img.get_fdata()[:]\n",
    "        mask_img = np.asarray(mask_img)\n",
    "        dilated_mask = np.zeros((nX, nY, nZ))\n",
    "        ratio = round(mask_img.shape[2]/nZ)\n",
    "        for k in range(nZ):\n",
    "            temp = ndimage.morphology.binary_dilation(mask_img[:, :, k*ratio], iterations=1) * 1\n",
    "            temp_img = Image.fromarray(np.uint8(temp*255))\n",
    "            dilated_mask[:, :, k] = np.array(temp_img.resize((nY, nX)))\n",
    "            \n",
    "        dilated_mask = (dilated_mask > 64).astype(int)\n",
    "        dilated_mask = torch.tensor(dilated_mask, dtype=torch.float, device=self.device)\n",
    "        return dilated_mask\n",
    "    \n",
    "    def apply_mask(self, img):\n",
    "        nT = img.shape[-1]\n",
    "        for i in range(nT):\n",
    "            img[:, :, :, i] = torch.mul(img[:, :, :, i], self.mask)\n",
    "        return img\n",
    "    \n",
    "    def apply_temporal_aug(self, img):\n",
    "        \"\"\"\n",
    "        Image shape: X, Y, Z, t=135\n",
    "        So, take any 15 random timesteps from the 135 available in ascending order \n",
    "        \"\"\"\n",
    "        total_timesteps = img.shape[3]\n",
    "        rand_timesteps = sorted(random.sample(range(0, total_timesteps), self.img_timesteps))\n",
    "        img = torch.tensor(np.take(img.cpu().numpy(), rand_timesteps, axis=3))\n",
    "        # Move time axes to the first place followed by X, Y, Z\n",
    "        img = img.permute(3, 0, 1, 2)\n",
    "        return img\n",
    "    \n",
    "    def find_weights(self):\n",
    "        weights = dict(self.weights)\n",
    "        key_max = max(weights.keys(), key=(lambda k: weights[k]))\n",
    "        max_value = weights[key_max]\n",
    "        for key in weights.keys():\n",
    "            weights[key] = max_value / weights[key]\n",
    "            \n",
    "        return weights\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.autograd as dif\n",
    "from torch.nn.modules.utils import _triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"2+1D MODULE\"\"\"\n",
    "\"\"\" -------------------------------------------------------------------------\"\"\"\n",
    "# R2Plus1D Convolution\n",
    "class SpatioTemporalConv(nn.Module):\n",
    "    r\"\"\"Applies a factored 3D convolution over an input signal composed of several input \n",
    "    planes with distinct spatial and time axes, by performing a 2D convolution over the \n",
    "    spatial axes to an intermediate subspace, followed by a 1D convolution over the time \n",
    "    axis to produce the final output.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input tensor\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        kernel_size (int or tuple): Size of the convolving kernel\n",
    "        stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
    "        padding (int or tuple, optional): Zero-padding added to the sides of the input during their respective convolutions. Default: 0\n",
    "        bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):\n",
    "        super(SpatioTemporalConv, self).__init__()\n",
    "\n",
    "        # if ints are entered, convert them to iterables, 1 -> [1, 1, 1]\n",
    "        kernel_size = _triple(kernel_size)\n",
    "        stride = _triple(stride)\n",
    "        padding = _triple(padding)\n",
    "\n",
    "        # decomposing the parameters into spatial and temporal components by\n",
    "        # masking out the values with the defaults on the axis that\n",
    "        # won't be convolved over. This is necessary to avoid unintentional\n",
    "        # behavior such as padding being added twice\n",
    "        spatial_kernel_size =  [1, kernel_size[1], kernel_size[2]]\n",
    "        spatial_stride =  [1, stride[1], stride[2]]\n",
    "        spatial_padding =  [0, padding[1], padding[2]]\n",
    "\n",
    "        temporal_kernel_size = [kernel_size[0], 1, 1]\n",
    "        temporal_stride =  [stride[0], 1, 1]\n",
    "        temporal_padding =  [padding[0], 0, 0]\n",
    "\n",
    "        # compute the number of intermediary channels (M) using formula \n",
    "        # from the paper section 3.5\n",
    "        intermed_channels = int(math.floor((kernel_size[0] * kernel_size[1] * kernel_size[2] * in_channels * out_channels)/ \\\n",
    "                            (kernel_size[1]* kernel_size[2] * in_channels + kernel_size[0] * out_channels)))\n",
    "\n",
    "        # the spatial conv is effectively a 2D conv due to the \n",
    "        # spatial_kernel_size, followed by batch_norm and ReLU\n",
    "        self.spatial_conv = nn.Conv3d(in_channels, intermed_channels, spatial_kernel_size,\n",
    "                                    stride=spatial_stride, padding=spatial_padding, bias=bias)\n",
    "        self.bn = nn.BatchNorm3d(intermed_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # the temporal conv is effectively a 1D conv, but has batch norm \n",
    "        # and ReLU added inside the model constructor, not here. This is an \n",
    "        # intentional design choice, to allow this module to externally act \n",
    "        # identical to a standard Conv3D, so it can be reused easily in any \n",
    "        # other codebase\n",
    "        self.temporal_conv = nn.Conv3d(intermed_channels, out_channels, temporal_kernel_size, \n",
    "                                    stride=temporal_stride, padding=temporal_padding, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn(self.spatial_conv(x)))\n",
    "        x = self.temporal_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MODEL\"\"\"\n",
    "\n",
    "\n",
    "\"\"\" Classifier \"\"\"\n",
    "class Custom3D(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(Custom3D, self).__init__()\n",
    "        self.ndf = params.ndf\n",
    "        self.nc = params.nT // params.nDivT\n",
    "        self.nClass = params.nClass\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            ## input is 15 x 54 x 64 x 50\n",
    "            SpatioTemporalConv(self.nc, self.ndf, 5, 2, 1, bias = False),\n",
    "            nn.ReLU(True),\n",
    "            ## state size. (ndf) x 26 x 31 x 24\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            SpatioTemporalConv(self.ndf * 1, self.ndf * 2, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm3d(self.ndf * 2),\n",
    "            nn.ReLU(True),\n",
    "            ## state size. (ndf*2) x 13 x 15 x 12\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            SpatioTemporalConv(self.ndf * 2, self.ndf * 4, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm3d(self.ndf * 4),\n",
    "            nn.ReLU(True),\n",
    "            ## state size. (ndf*4) x 6 x 7 x 6\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            SpatioTemporalConv(self.ndf * 4, self.ndf * 4, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm3d(self.ndf * 4),\n",
    "            nn.ReLU(True),\n",
    "            ## state size. (ndf*2) x 3 x 3 x 3\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            SpatioTemporalConv(self.ndf * 4, self.ndf * 2, 3, 1, 0, bias = False),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        \n",
    "        self._to_linear = None\n",
    "        x = torch.randn(1, self.nc, params.nX, params.nY, params.nZ)\n",
    "        self.convs(x)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._to_linear, self.ndf * 1)\n",
    "\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(self.ndf * 1, self.nClass),\n",
    "        )\n",
    "        \n",
    "    def convs(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        \n",
    "        # This is to make sure that we don't have to worry about the shape from the convolutional layers\n",
    "        # before sending the input to the FC layers\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = int(x[0].shape[0]*x[0].shape[1]*x[0].shape[2]*x[0].shape[3])\n",
    "            \n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FmriDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0,\n",
       " 1: 3.9206349206349205,\n",
       " 2: 7.484848484848484,\n",
       " 3: 7.264705882352941,\n",
       " 4: 5.369565217391305}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main file code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = edict({\n",
    "    'path': '/data/fmri',\n",
    "    'nGPU': 2,\n",
    "    'nEpochs': 10,\n",
    "    'nBacks': 2,\n",
    "    'nTasks': 4,\n",
    "    'nClass': 5,\n",
    "    'batchSize': 10,\n",
    "    'nT': 135,\n",
    "    'nX': 57,\n",
    "    'nY': 68,\n",
    "    'nZ': 49,\n",
    "    'nDivT': 9,\n",
    "    'ndf': 64,\n",
    "    'lr': 0.001,\n",
    "    'beta1': 0.5,\n",
    "    'beta2': 0.999\n",
    "})\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.FloatTensor([data.class_weights[i] for i in range(5)]).to(device)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Custom3D(params=params).to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_length(total, test_pct=0.2):\n",
    "    train_count = int((1-test_pct)*total)\n",
    "    test_count = total - train_count\n",
    "    return train_count, test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count, test_count = train_test_length(total=len(data), test_pct=0.2)\n",
    "train_count, test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = random_split(data, [train_count, test_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=params.batchSize, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=params.batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net):\n",
    "    for epoch in range(params.nEpochs):\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f'Epoch: {epoch} | Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "fmri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
