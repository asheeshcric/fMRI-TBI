{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import nilearn as nil\n",
    "from nilearn import image as nil_image\n",
    "import numpy as np\n",
    "\n",
    "from scipy import ndimage\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.autograd as dif\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "\n",
    "from torch import optim\n",
    "from torch.nn.modules.utils import _triple\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# This is imported to fix any data error in a batch\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Custom import\n",
    "from train_test_set import train_test_subs, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FmriModel(nn.Module):\n",
    "\n",
    "    def __init__(self, params):\n",
    "        super(FmriModel, self).__init__()\n",
    "\n",
    "        self.ndf = params.ndf\n",
    "        # \"nc\" is the number of channels in the input image (t=nc in this case)\n",
    "        self.nc = params.img_timesteps\n",
    "        self.nClass = params.nClass\n",
    "\n",
    "        # Input to the model is (t, 57, 68, 49) <== (t, x, y, z)\n",
    "        # 't' can change based on the \"img_timesteps\" value (number of timesteps to be sampled from one scan)\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(params.nX, self.ndf, 5, 2, bias=False),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(self.ndf*1, self.ndf*2, 5, 2, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf*2),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(self.ndf*2, self.ndf*4, 5, 2, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf*4),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self._to_linear, self._to_lstm = None, None\n",
    "        x = torch.randn(params.batchSize*self.nc,\n",
    "                        params.nX, params.nY, params.nZ)\n",
    "        self.convs(x)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=3840, hidden_size=256,\n",
    "                            num_layers=1, batch_first=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(256, self.ndf * 1)\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(self.ndf * 1, self.nClass),\n",
    "        )\n",
    "\n",
    "    def convs(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            # First pass: done to know what the output of the convnet is\n",
    "            self._to_linear = int(x[0].shape[0]*x[0].shape[1]*x[0].shape[2])\n",
    "            # For LSTM input, divide by batch_size and time_steps (i.e. / by self.nc and 1)\n",
    "            self._to_lstm = int(self._to_linear/self.nc)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, timesteps, c, h, w = x.size()\n",
    "        \n",
    "        # For each timestep, pass the data into the CNN\n",
    "        for t in timesteps:\n",
    "            # Passing the 't_th' timestep of the whole batch to the CNN\n",
    "            x_input = x[:, t, :, :, :]\n",
    "            x_input = self.convs(x_input)\n",
    "            print(f'Output of batch after CNN: {x_input.size()}')\n",
    "        \n",
    "        # Merge batch_size and timesteps into one dimension\n",
    "        x = x.view(batch_size*timesteps, c, h, w)\n",
    "        cnn_out = self.convs(x)\n",
    "\n",
    "        # Prepare the output from CNN to pass through the LSTM layer\n",
    "        r_in = cnn_out.view(batch_size, timesteps, -1)\n",
    "\n",
    "        # Flattening is required when we use DataParallel\n",
    "        self.lstm.flatten_parameters()\n",
    "\n",
    "        # Get output from the LSTM\n",
    "        r_out, (h_n, h_c) = self.lstm(r_in)\n",
    "\n",
    "        # Pass the output of the LSTM to FC layers\n",
    "        r_out = self.fc1(r_out[:, -1, :])\n",
    "        r_out = self.fc2(r_out)\n",
    "\n",
    "        # Apply softmax to the output and return it\n",
    "        return F.log_softmax(r_out, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FmriDataset(Dataset):\n",
    "\n",
    "    def __init__(self, params, data_dir='/data/fmri/data', mask_path='/data/fmri/mask/caudate._mask.nii',\n",
    "                 img_shape=(57, 68, 49, 135)):\n",
    "        self.data_dir, self.params = data_dir, params\n",
    "        self.img_timesteps = params.img_timesteps\n",
    "        self.num_classes = params.nClass\n",
    "        self.device = torch.device(\n",
    "            \"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.mask_path, self.img_shape = mask_path, img_shape\n",
    "        self.samples = []\n",
    "        # Initialize the image indexes with their scores\n",
    "        self.index_data()\n",
    "        # self.mask = self.read_mask()\n",
    "        self.class_weights = self.find_weights()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path, score = self.samples[idx]\n",
    "            score = self.get_class(score)\n",
    "            img = self.read_image(img_path)\n",
    "            # img = self.apply_mask(img)\n",
    "            img = self.apply_temporal_aug(img)\n",
    "            return img, score\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def index_data(self):\n",
    "        \"\"\"\n",
    "        Stores all the image_paths with their respective scores/classes in the \n",
    "        \"\"\"\n",
    "        self.weights = {i: 0 for i in range(self.num_classes)}\n",
    "        for sub in os.listdir(self.data_dir):\n",
    "            if sub not in self.params.subs:\n",
    "                # Don't consider subjects that are not in the subs set\n",
    "                continue\n",
    "            sub_dir = os.path.join(self.data_dir, sub)\n",
    "            preproc_dir = os.path.join(sub_dir, f'{sub}.preproc')\n",
    "            for img_name in os.listdir(preproc_dir):\n",
    "                img_path = os.path.join(preproc_dir, img_name)\n",
    "                score = self.get_score(sub_dir, img_name)\n",
    "                score_class = self.get_class(score)\n",
    "                # Since we are randomly sampling 30 timesteps from each scan of 135 timesteps,\n",
    "                # I am considering the same image for \"n\" times so that we have more data to train\n",
    "                n = 5\n",
    "                for k in range(n):\n",
    "                    self.weights[score_class] += 1\n",
    "                    self.samples.append((img_path, score))\n",
    "\n",
    "    def get_class(self, score):\n",
    "        \"\"\"\n",
    "        Categorize each score into one of the five classes (bins)\n",
    "        Returns values from 0-5 (6 classes)\n",
    "        Classes: (0, 10), (10, 20), (20, 40), (40, 60), (60, 80), (80, 100)\n",
    "        \"\"\"\n",
    "        if score < 10:\n",
    "            return 0\n",
    "        elif score >= 10 and score < 20:\n",
    "            return 1\n",
    "        elif score >= 20 and score < 40:\n",
    "            return 2\n",
    "        elif score >= 40 and score < 60:\n",
    "            return 3\n",
    "        elif score >= 60 and score < 80:\n",
    "            return 4\n",
    "        else:\n",
    "            return 5\n",
    "\n",
    "    def get_score(self, sub_dir, img_name):\n",
    "        score_file = '0back_VAS-f.1D' if '0back' in img_name else '2back_VAS-f.1D'\n",
    "        score_path = os.path.join(sub_dir, score_file)\n",
    "        with open(score_path, 'r') as s_f:\n",
    "            scores = [int(str(score.replace('\\n', ''))) for score in s_f]\n",
    "\n",
    "        task_num = img_name.split('.')[1]\n",
    "        score_num = int(task_num[-1:])\n",
    "        return scores[score_num]\n",
    "\n",
    "    def read_image(self, img_path):\n",
    "        nX, nY, nZ, nT = self.img_shape\n",
    "        img = nil_image.load_img(img_path)\n",
    "        img = img.get_fdata()[:nX, :nY, :nZ, :nT]\n",
    "        img = torch.tensor(img, dtype=torch.float, device=self.device)\n",
    "        img = (img - img.mean()) / img.std()\n",
    "        return img\n",
    "\n",
    "    def read_mask(self):\n",
    "        nX, nY, nZ, _ = self.img_shape\n",
    "        mask_img = nil.image.load_img(self.mask_path)\n",
    "        mask_img = mask_img.get_fdata()[:]\n",
    "        mask_img = np.asarray(mask_img)\n",
    "        dilated_mask = np.zeros((nX, nY, nZ))\n",
    "        ratio = round(mask_img.shape[2]/nZ)\n",
    "        for k in range(nZ):\n",
    "            temp = ndimage.morphology.binary_dilation(\n",
    "                mask_img[:, :, k*ratio], iterations=1) * 1\n",
    "            temp_img = Image.fromarray(np.uint8(temp*255))\n",
    "            dilated_mask[:, :, k] = np.array(temp_img.resize((nY, nX)))\n",
    "\n",
    "        dilated_mask = (dilated_mask > 64).astype(int)\n",
    "        dilated_mask = torch.tensor(\n",
    "            dilated_mask, dtype=torch.float, device=self.device)\n",
    "        return dilated_mask\n",
    "\n",
    "    def apply_mask(self, img):\n",
    "        nT = img.shape[-1]\n",
    "        for i in range(nT):\n",
    "            img[:, :, :, i] = torch.mul(img[:, :, :, i], self.mask)\n",
    "        return img\n",
    "\n",
    "    def apply_temporal_aug(self, img):\n",
    "        \"\"\"\n",
    "        Image shape: X, Y, Z, t=135\n",
    "        So, e.g: take any 30 random timesteps from the 135 available in ascending order \n",
    "        \"\"\"\n",
    "        total_timesteps = img.shape[3]\n",
    "        rand_timesteps = sorted(random.sample(\n",
    "            range(0, total_timesteps), self.img_timesteps))\n",
    "        # Move time axes to the first place followed by X, Y, Z\n",
    "        img = img.permute(3, 0, 1, 2)\n",
    "        img = torch.tensor(np.take(img.cpu().numpy(), rand_timesteps, axis=0))\n",
    "        return img\n",
    "\n",
    "    def find_weights(self):\n",
    "        weights = dict(self.weights)\n",
    "        key_max = max(weights.keys(), key=(lambda k: weights[k]))\n",
    "        max_value = weights[key_max]\n",
    "        for key in weights.keys():\n",
    "            # Add 1 to the denominator to avoid divide by zero error (in some cases)\n",
    "            weights[key] = max_value / (weights[key]+1)\n",
    "\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    # Function to catch errors while reading a batch of fMRI scans\n",
    "    # Removes any NoneType values from the batch to prevent errors while training\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return default_collate(batch)\n",
    "    \n",
    "\n",
    "def train_test_length(total, test_pct=0.2):\n",
    "    train_count = int((1-test_pct)*total)\n",
    "    test_count = total - train_count\n",
    "    return train_count, test_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, loss_function, optimizer, test_loader):\n",
    "    print('Training...')\n",
    "    for epoch in range(params.nEpochs):\n",
    "        for batch in tqdm(train_loader):\n",
    "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        \n",
    "        _, _, train_acc = test(net, train_loader)\n",
    "        _, _, test_acc = test(net, test_loader)\n",
    "\n",
    "        print(f'Epoch: {epoch} | Loss: {loss} | Train Acc: {train_acc} | Test Acc: {test_acc}')\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def test(net, test_loader):\n",
    "    print('Testing...')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    preds = []\n",
    "    actual = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            if not data:\n",
    "                continue\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            class_outputs = net(inputs)\n",
    "            _, class_prediction = torch.max(class_outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (class_prediction == labels).sum().item()\n",
    "            preds.extend(list(class_prediction.to(dtype=torch.int64)))\n",
    "\n",
    "            actual.extend(list(labels.to(dtype=torch.int64)))\n",
    "\n",
    "    acc = 100*correct/total\n",
    "    # print(f'Accuracy: {acc}')\n",
    "    return preds, actual, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: LR: 0.0001 | Epochs: 10 | K-folds: 1 | BatchSize: 10 | Sample timesteps: 50\n"
     ]
    }
   ],
   "source": [
    "# Initial parameters defined\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "k_fold = 1\n",
    "params.nEpochs = 10\n",
    "accs = []\n",
    "cf_matrix = []\n",
    "learning_rate = 0.0001\n",
    "sample_timesteps = 50\n",
    "params.update({'img_timesteps': sample_timesteps})\n",
    "\n",
    "print(f'Parameters: LR: {learning_rate} | Epochs: {params.nEpochs} | K-folds: {k_fold} | BatchSize: {params.batchSize} | Sample timesteps: {sample_timesteps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For only one fold for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and testing subjects from the dataset\n",
    "train_subs, test_subs = train_test_subs(test_pct=0.2)\n",
    "\n",
    "# Add 'subs' key in the params to track which subjects to use to create both trainset and testset\n",
    "params.update({'subs': train_subs})\n",
    "trainset = FmriDataset(params=params)\n",
    "params.update({'subs': test_subs})\n",
    "testset = FmriDataset(params=params)\n",
    "\n",
    "# Identify the training set class weights based on their occurences in the training data\n",
    "class_weights = torch.FloatTensor(\n",
    "    [trainset.class_weights[i] for i in range(params.nClass)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "net = FmriModel(params=params).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FmriModel(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(57, 64, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (lstm): LSTM(3840, 256, batch_first=True)\n",
      "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the summary of the model\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(k_fold):\n",
    "    train_subs, test_subs = train_test_subs(test_pct=0.2)\n",
    "    # print(f'Train-subs: {len(train_subs)}')\n",
    "    # print(f'Test-subs: {len(test_subs)}')\n",
    "    params.update({'subs': train_subs})\n",
    "    trainset = FmriDataset(params=params)\n",
    "    params.update({'subs': test_subs})\n",
    "    testset = FmriDataset(params=params)\n",
    "\n",
    "    class_weights = torch.FloatTensor(\n",
    "        [trainset.class_weights[i] for i in range(params.nClass)]).to(device)\n",
    "    # Initialize the model\n",
    "    net = FmriModel(params=params).to(device)\n",
    "    # Distributed training on multiple GPUs if available\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "    print(f'Number of GPUs available: {n_gpus}')\n",
    "    if (device.type == 'cuda') and (n_gpus > 1):\n",
    "        net = nn.DataParallel(net, list(range(n_gpus)))\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        trainset, batch_size=params.batchSize, shuffle=True, collate_fn=my_collate)\n",
    "    test_loader = DataLoader(\n",
    "        testset, batch_size=params.batchSize, shuffle=True, collate_fn=my_collate)\n",
    "    \n",
    "    # You can use my_collate() function inside the dataloader to check for errors while reading corrupted scans\n",
    "\n",
    "    net = train(net, train_loader, loss_function, optimizer, test_loader)\n",
    "    # Save the model checkpoint\n",
    "    current_time = datetime.now()\n",
    "    current_time = current_time.strftime(\"%m%d%Y%H_%M\")\n",
    "    torch.save(net.state_dict(), f'{current_time}-scans-5-fold-{k}.pth')\n",
    "    preds, actual, acc = test(net, test_loader)\n",
    "    accs.append(acc)\n",
    "\n",
    "    # For confusion matrix\n",
    "    preds = [int(k) for k in preds]\n",
    "    actual = [int(k) for k in actual]\n",
    "\n",
    "    cf = confusion_matrix(actual, preds, labels=list(range(params.nClass)))\n",
    "    cf_matrix.append(cf)\n",
    "    with open('cf_matrices.txt', 'a') as cf_file:\n",
    "        cf_file.write(str(cf) + '\\n')\n",
    "\n",
    "\n",
    "print(cf_matrix)\n",
    "print(accs)\n",
    "print(f'Avg Accuracy: {sum(accs)/len(accs)}')\n",
    "print(f'Parameters: LR: {learning_rate} | Epochs: {params.nEpochs} | K-folds: {k_fold} | BatchSize: {params.batchSize} | Sample timesteps: {sample_timesteps}')\n",
    "\n",
    "with open('abc.txt', 'w') as abc_file:\n",
    "    for cf in cf_matrix:\n",
    "        abc_file.write(f'{cf}\\n')\n",
    "    abc_file.write(f'{accs}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "fmri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
